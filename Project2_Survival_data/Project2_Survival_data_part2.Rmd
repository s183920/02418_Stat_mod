---
title: 'Project2: Survival data part 2'
output:
  html_document:
    theme: united
    toc: yes
    toc_collapsed: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- # Packages -->

```{r Packages, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(GGally)
library(magrittr)
library(survival)
```


# Data

## Load
```{r Data load, include = FALSE}
act_data <- read.delim("../Data/actg320.txt", header = T, sep = "\t")
log_data <-  read.delim("../Data/Logistic.txt", header = T, sep = "\t")
  # bind_rows(data.frame(AZT = "Total", AIDS_yes = sum(.$AIDS_yes), n= sum(.$n)))

```


# Analysis of the binary data

## Logistic regression model
Fit a logistic regression model for the binary outcome AIDS=”yes” versus
AIDS=”no” with the explanatory variable treatment with AZT (Yes,
NO). Present the odds ratio for the effect of AZT on AIDS with 95%
confidence interval and interpret the result in words.

Tag exp(b1) for at få odds se s. 155

indsæt værdier fundet i tidligere rapport

estiamte parameters in regression model
```{r}
beta0 <- -1.036
beta1 <- -0.7218
exp(beta0)/(1+exp(beta0))
exp(beta0+beta1)/(1+exp(beta0+beta1))
```

```{r}
#verison 1
# dat <- data.frame(AZT = rep(1,25), AIDS = rep(1, 25)) %>%
#   bind_rows(data.frame(AZT = rep(1,170-25), AIDS = rep(0, 170-25))) %>%
#   bind_rows(data.frame(AZT = rep(0,44), AIDS = rep(1, 44))) %>%
#   bind_rows(data.frame(AZT = rep(0,168-44), AIDS = rep(0, 168-44)))
# 
# dat = data.frame(y=c(0,1,0,1,0), x=c(1,1,0,0,0))
# 
# logReg1 <- glm(y~x, data=dat, family = binomial)
# summary(logReg1)

#previous version

logL_partial <- function(theta, data, AZT = TRUE){
    y = if (AZT) {data[1,2]} else {data[2,2]} %>% as.numeric()
    n = if (AZT) {data[1,3]} else {data[2,3]} %>% as.numeric()
    false = n-y
    
    y*((theta[1] + theta[2] * AZT) * 1 - log(1+exp(theta[1]+theta[2]*AZT))) + false*((theta[1] + theta[2] * AZT) * 0 - log(1+exp(theta[1]+theta[2]*AZT)))
}

nlogL <- function(theta, data){
     - (logL_partial(theta,data, F) + logL_partial(theta,data, T))
  # - (logL_partial(theta, data, T)/logL_partial(theta, data, F))
}

lower <- c(-Inf, -Inf)
opt <- nlminb(c(0, 0), nlogL, lower = lower, data = log_data, hessian = T)

print(exp(opt$par[2]))

b1 <- c(-1.2791, -0.721766, -0.1827) #taget fra tidligere rapport
exp(b1)



opt1 <- nlminb(c(0, 0), logL_partial, lower = lower, data = log_data, AZT = T, hessian = T)
opt2 <- nlminb(c(0, 0), logL_partial, lower = lower, data = log_data, AZT = F, hessian = T)
opt1$par
opt2$par
```

en værdi på 0.49 betyder at der er ca halv så stor chance for at få AIDS, når du får AZT ift. hvis du ikke får AZT
for hver gang AZT stiger med 1, falder dødeligheden/chancen for AIDS med en faktor 0.49

```{r}
log_data

aids_yes <- log_data$AIDS_yes
n <- log_data$n

aids_yes[1]*(n[2]-aids_yes[2])/((n[1]-aids_yes[1])*aids_yes[2])
```


## Likelihood ratio test

$$Q=-2 \log \frac{L\left(\theta_{0}\right)}{L(\hat{\theta})}$$
Vi bruger profile likelihood for $\beta_1$ for at udregne test-statistic Q. En p-værdi kan derfra opnås ved at finde hale værdien til denne værdi i en $\chi^2$ fordeling med 1 frihedsgrad.

```{r}
logL_partial2 <- function(b0, b1, data, AZT = TRUE){
    y = if (AZT) {data[1,2]} else {data[2,2]} %>% as.numeric()
    n = if (AZT) {data[1,3]} else {data[2,3]} %>% as.numeric()
    false = n-y
    
    y*((b0 + b1 * AZT) * 1 - log(1+exp(b0+b1*AZT))) + false*((b0 + b1 * AZT) * 0 - log(1+exp(b0+b1*AZT)))
}


nlogL2 <- function(theta, b1, data){
      -(logL_partial2(theta[1], b1,data, F) + logL_partial2(theta[1],b1,data, T))
}

profile_b1 <- function(b1, data){
  opt <- nlminb(c(0), nlogL2, lower = c(-Inf), data = log_data, b1 = b1)
  # optimize(logL)
  b0 <- opt$par
  -nlogL2(c(b0),b1,data)
}



MLE_b1 <- optimize(profile_b1, c(-5,5), data = log_data, maximum = T)$maximum

Q <- function(theta){
  (profile_b1(MLE_b1, log_data)-profile_b1(theta, log_data))
}
CI <- seq(-5, 5, 0.1) 
vals <- sapply(CI,Q)
plot(CI, -vals/max(vals) , "l", xlab = expression(beta[1]))
abline(-1/2*qchisq(0.95, 1)/max(vals), 0)

# exp(-profile_b1(MLE_b1, log_data))/exp(-1/2*qchisq(0.95, 1))

CI <- CI[vals < 1/2*qchisq(0.95, 1)]
cat("Confidence interval via the likelihood ratio test: ", min(CI), max(CI))

q <- -2*(profile_b1(0, log_data)-profile_b1(MLE_b1, log_data))
q
p_val <- pchisq(q, df = 1, lower.tail = F) #signifcant
cat("\nP-value for likelihood ratio test: ", p_val)
```



## The wald test

Først udregnes en test-statistic $z=\frac{\hat{\theta}-\theta_{0}}{\operatorname{se}\left(\hat{\theta}\right)}$
Hvor $\theta_0 = 0$, da dette er vores nul-hypotese. og $s e\left(\hat{\theta}_{i}\right)=\sqrt{\left(I^{-1}(\hat{\boldsymbol{\theta}})\right)_{i i}}$. Værdien af z kan nu indsættes i fordelingsfunktionen for en standard normal fordeling for at opnå en p-værdi.

Et konfidens interval kan fidnes ved: $\hat{\theta}_{i} \pm z_{1-\alpha / 2} \operatorname{se}\left(\hat{\theta}_{i}\right)$

```{r}
hess <- numDeriv::hessian(nlogL, opt$par, data = log_data)
se <- sqrt(solve(hess)[2,2])
CI_b1 <- opt$par[2]+c(-1,1)*qnorm(0.975)*se
cat("The confidence interval for the treatment parameter with the wald test is: ", CI_b1)

cat("\nThe p-value with the wald test is: ", pnorm(MLE_b1/se))
```


## Score test

test-statistic givet ved $z=\frac{S\left(\theta_{0}\right)}{\sqrt{\mathcal{I}\left(\theta_{0}\right)}}$



Log likelihood for logistic model:
$$\log L\left(\beta_{0}, \beta_{1}\right)=\sum_{i}\left[\left(\beta_{0}+\beta_{1} \cdot G_{i}\right) y_{i}-\log \left(1+\exp \left(\beta_{0}+\beta_{1} \cdot G_{i}\right)\right)\right]$$
Score function (first derivative wrt. $\beta_1$):
$$
S(\theta) = \sum _iG y-\frac{G e^{\theta G+\beta_0}}{1+e^{\theta G+\beta_0}}
$$

Information (negative of second derivative wrt. $\beta_1$):
$$
I(\theta) = \sum \frac{G e^{\theta G+\beta_0}}{\left(1+e^{\theta G+\beta_0}\right)^{2}}
$$

```{r}
logL_partial3 <- function(b0, b1, data, AZT = TRUE){
    y = if (AZT) {data[1,2]} else {data[2,2]} %>% as.numeric()
    n = if (AZT) {data[1,3]} else {data[2,3]} %>% as.numeric()
    false = n-y
    
    y*((b0 + b1 * AZT) * 1 - log(1+exp(b0+b1*AZT))) + false*((b0 + b1 * AZT) * 0 - log(1+exp(b0+b1*AZT)))
}


nlogL3 <- function(b0, theta, data){
      -(logL_partial2(b0, theta,data, F) + logL_partial2(b0, theta,data, T))
}


b0_h0 <- function(theta0){
  optimize(nlogL3, c(-5, 5), theta = theta0, data = log_data)$minimum
}



score_partial <- function(theta, b0, AZT = T){
  "
  AZT = G
  "
  data <- log_data
  y = if (AZT) {data[1,2]} else {data[2,2]} %>% as.numeric()
  n = if (AZT) {data[1,3]} else {data[2,3]} %>% as.numeric()
  false = n-y
  
  y*(1*AZT-AZT*exp(theta*AZT+b0)/(1+exp(theta*AZT+b0))) + false*(0*AZT-AZT*exp(theta*AZT+b0)/(1+exp(theta*AZT+b0)))
}

score <- function(theta){
  score_partial(theta, b0_h0(theta), AZT = T)+score_partial(theta, b0_h0(theta), AZT = F)
}

info_partial <- function(theta, b0, AZT = T){
  data <- log_data
  y = if (AZT) {data[1,2]} else {data[2,2]} %>% as.numeric()
  n = if (AZT) {data[1,3]} else {data[2,3]} %>% as.numeric()
  false = n-y
  
  y*(AZT*exp(theta*AZT+b0)/(1+exp(theta*AZT+b0))^2) + false*(AZT*exp(theta*AZT+b0)/(1+exp(theta*AZT+b0))^2)
}

info <- function(theta){
  info_partial(theta, b0_h0(theta), AZT=T) + info_partial(theta, b0_h0(theta), AZT=F)
}

z <- score(0)/sqrt(info(0))

cat("The test statistic for H0: theta = 0 is ", z, ", which yields a p-vlaue of ", 2*pnorm(z))
cat("\nThe test statistic for H0: theta = 0 is ", z, ", which yields a p-vlaue of ", 1-pchisq(z^2, df = 1))

``` 

As seen above the p-value leans towards a rejection of the null hypothesis $\beta_1 = 0$ on a 6.5 % significance level and the score test there shows that AZT and $\beta_1$ has an effect. This does however not hold on the standard 5 % significance level, and the score test can therefore not reject the null hypothesis of $\beta_1 = 0$


# 1 Analysis of survival time data
We wish to test for a difference between the 2 groups.

## 1.1 Descriptive statistics 

### How many patients got AIDS or died in the 2 treatment groups? And how long was the total follow up time in the 2 groups?

The total follow up time is the time from the beginning of the study till the end of the study $t_f - t_0$ ie. the max time observed.

```{r}
tx0 = act_data %>% filter(tx == 0)
tx1 = act_data %>% filter(tx == 1)
ftime0 = tx0$time %>% max()  # Total follow up time
ftime1 = tx1$time %>% max()  # Total follow up time
nevents0 = tx0$event %>% sum() # Number of events in no treatment group
nevents1 = tx1$event %>% sum() # Number of events in treatment group
cat("The total follow up time in the treatment groups was: ", ftime1, ".The number of events was: ", nevents1, "\nThe total follow up time in the no treatment group was: ", ftime0, ".The number of events was: ", nevents0)
```

### Plot the survival functions in the 2 treatments groups, which group seems to be doing best?

The Kaplan Meier estimate of the survival function is used:
$$S_{KM}(t) = \sum_{t_i < t} \frac{R_t - d_t}{R_t}$$
Log-log confidence intervals are estimated:
$$
\left(\hat{c}_{l} ; \hat{c}_{u}\right)=\log [-\log (\hat{S}(t))] \pm z_{1-\alpha / 2} \sqrt{\operatorname{Var}[\log (-\log (\hat{S}(t)))]}
$$
with:
$$
Var[log(-log[S(t)])] = \frac{1}{[S(t)]^2}\sum_{t_i < t} \frac{d_i}{R_i(R_i - d_i)}
$$
To get the normal estimates of $\left(\hat{c}_{l} ; \hat{c}_{u}\right)$ these are reversed by: $\left( exp\left[-exp(\hat{c}_{l})\right] ; exp \left[ -exp(\hat{c}_{u})\right] \right)$

The cumulative incidence function $F(t) = 1 - S(t)$ is also plotted to the right

```{r}
# KM estimate of survival function for both groups (tx == 0 and tx == 1) with log-log confidence intervals
Surv.Bygroup <- survfit(Surv(time,event == 1) ~ tx, conf.type = "log-log",
                        data = act_data)

# Plotting
par(mfrow = c(1,2))
plot(Surv.Bygroup, col = 2:3, lwd = 2, conf.int =  T, ylim = c(0.8,1),
     xlab = "Time (days)",
     ylab = "Estimated Survival Prob.", main = "Kaplan Meier Estimate of Survival Function")

legend("bottomleft", legend = c("Treatment", "No treamtent"), col = c("green", "red"), lty = c(1,1))

plot(Surv.Bygroup, col = 2:3, conf.int = T, fun=function(x) { 1- x }, las = 1, 
     xlab = "Time (days)", 
     ylab = "Estimated Prob. of AIDS / Death", lwd = 2, ylim = c(0,0.2), main = "Cumulative Incidence Function")
legend("topleft", legend = c("Treatment", "No treamtent"), col = c("green", "red"), lty = c(1,1))
```

### Compare the two treatment groups using a log - rank test
We compare the two groups by setting up the table for each surval time $t_i$
$$
\begin{array}{|c|c|c|c|}
\hline \text { Event/Group } & 1 & 0 & \text { Total } \\
\hline \text { Dead } & d_{1 i} & d_{0 i} & d_{i} \\
\text { Not dead } & R_{1 i}-d_{1 i} & R_{0 i}-d_{0 i} & R_{i}-d_{i} \\
\text { At risk } & R_{1 i} & R_{0 i} & R_{i} \\
\hline
\end{array}
$$
The expected number of deaths / AIDS (assuming equal survival probability) is 
$$\hat{e}_{1 i}=R_{i} \frac{R_{1 i}}{R_{i}} \frac{d_{i}}{R_{i}}=\frac{R_{1 i} d_{i}}{R_{i}}$$
A $\chi^2$ test with 1 degree of freedom can be used, with test statistic:
$$\chi^2=\frac{\left(\sum_{i=1}^{m} w_{i}\left(d_{1 i}-\hat{e}_{1 i}\right)\right)^{2}}{\sum_{i=1}^{m} w_{i}^{2} \hat{v}_{1 i}}$$
Where $v_i$ is a variance estimate defined by:
$$\hat{v}_{i}=\frac{R_{1, i} R_{2, i} d_{i}\left(R_{i}-d_{i}\right)}{R_{i}^{2}\left(R_{i}-1\right)}$$
And $w_i$ is a weight. If $w_i = 1$ we test is called log rank test, which is what we wish to do
```{r}
# Log rank test:
survdiff(Surv(time, event == 1) ~ tx, data = act_data, rho = 1)
```
The result is $\chi^2 = 10.3$ on 1 degrees of freedom. This gives the p-value $p = 0.001$. The difference between the 2 survival functions is significant. 







## 1.2 Parametric Survival Models
### Fit parametric survival models containing treatment (tx) and CD4 count (cd4) as explantory variables.

Fitting the 3 models:

Exponential:   $logT = \mathbf{x}^T\mathbf{b} + \epsilon^*$, $exp(\epsilon^*) \sim Exp(\lambda = 1)$
  
Weibull:   $logT =  \mathbf{x}^T\mathbf{b} + \sigma \epsilon^*$, $exp(\sigma \epsilon^*) \sim Weibull(\lambda = 1, k =\frac{1}{\lambda})$

Log logistic:   $logT =  \mathbf{x}^T\mathbf{b} + \sigma \epsilon^*$, $\epsilon^* \sim Logistic(\mu = 0, \sigma = 1)$

```{r}
mod_exp <- survreg(Surv(time, event == 1) ~ tx + cd4, data = act_data,
                 dist = "exponential")
mod_weibull <- survreg(Surv(time, event == 1) ~ tx + cd4, data = act_data,
                 dist = "weibull")
mod_loglogistic <- survreg(Surv(time, event == 1) ~ tx + cd4, data = act_data,
                 dist = "loglogistic")
summary(mod_exp)
summary(mod_weibull)
summary(mod_loglogistic)

```

Comparing the 3 models using AIC

```{r}
cat("Expontential:",AIC(mod_exp), "Weibull:",AIC(mod_weibull), "Log Logistic:",AIC(mod_loglogistic))

```
The lowest AIC is for the log logistic model. This is one with the best fit. 

Showing a table of estimates of the log logistic model and their 95 % confidence intervals
```{r}
est = summary(mod_loglogistic)$table[,1]
std = summary(mod_loglogistic)$table[,2]
# Confidence intervals 
CI1 = est[1] + c(-1,1) * qnorm(0.975) * std[1]
CI2 = est[2] + c(-1,1) * qnorm(0.975) * std[2]
CI3 = est[3] + c(-1,1) * qnorm(0.975) * std[3]
CI4 = est[4] + c(-1,1) * qnorm(0.975) * std[4]
# Table of estimates and confidence intervals
(C = cbind(est,matrix(c(CI1, CI2, CI3, CI4), nrow = 4  , byrow = T )) %>% data.frame() %>% plyr::rename(., c("est" = "Estimates", "V2" = "Lower","V3" = "Upper")))
```
### Time ratio
Compute time ratio for treatment effect for the treatment effect. Compute the time ratio for the effect of increasing CD4 count with 50.

Time ratio is a measure of how much a covariate in the model affects the time to event. We will look at the mean time to event $t_{50}$

$$TR_{tx}(tx, cd4) = \frac{t_{50}(tx = 1, cd4 = c)}{t_{50}(tx =0, cd4 = c)} = exp(\beta_1)$$
$$TR_{cd4}(tx, cd4) = \frac{t_{50}(tx = t, cd4 = c+1)}{t_{50}(tx =t, cd4 = c)} = exp(\beta_2)$$

This means we fixed every other covariates and looke in the change of a single covariate. $TR_{tx}$ gives the effect on the median time to event between the 2 treatment groups for persons with the same cd4 level. $TR_{cd4}$ gives the effect of an increase of 1 in cd4 for the same treatment group. If instead we wish to see the effect with an increase of 50: 
$exp(\beta_{i} * 50)$
With confidence intervals:
$$CI_{TR} = exp(\hat{\beta_i} \pm z_{1-\alpha/2}SE(\hat{\beta_i}))$$

This is done below:
```{r}
exp(c(est["tx"], C[2,2], C[2,3]))
exp(c(est["cd4"]*50, C[3,2]*50, C[3,3]*50))

```

The median time to event is 2.32 higher in the treatment group ie. people in the treament group lives longer.

The median time to even is 2.82 higher with an increase of 50 in cd4. People with higher cd4 lives longer.

### Cox Snell Residuals
The Cox Snell Residuals $r_i$ are defined as $r_i = -log(\hat{S}_{t_i}) = \hat{H}(t_i)$ at time $t_i$ and $\hat{S}(t_i)$ is the predicted survival function from the model.

For some reason it is known that the fitted model is good if these residuals follows a $exp(1)$ distribution.

The survival function of $exp(1)$ is $S_{exp(1)} = exp(-x)$. From this we get
$$-log S_{exp}(r_i) = -log (exp(-r_i)) = r_i$$
If we use the non parametric Kaplan Meier estimate of the survival function of $r_i$ we can compare this to the observed Cox snell residuals

$$(r_i , -log[S_{KM}(r_i)])$$
This should follow a straight line with slope 1 and intercept 0, if the model is a good fit.

This is done for the three models below (should only be done for log logistic):
```{r}
coxsnell1 <- log(1+exp((log(act_data$time) - mod_loglogistic$linear.predictors)/mod_loglogistic$scale))
coxsnell2 <- exp((log(act_data$time) - mod_weibull$linear.predictors)/mod_weibull$scale)
coxsnell3 <- act_data$time * exp(-mod_exp$linear.predictors)
act_data$CS1 <- coxsnell1
act_data$CS2 <- coxsnell2
act_data$CS3 <- coxsnell3

par(mfrow = c(3,1))
SurvKM0 <- survfit(Surv(CS1, event == 1)~1, data = act_data)
plot(SurvKM0$time, -log(SurvKM0$surv), main = "Cox Snell - Log Logistic", xlab = "Cox Snell residuals", ylab = "-log(S(t))")

abline(a = 0, b = 1, lty = 2, lwd = 3, col = "red")
SurvKM1 <- survfit(Surv(CS2, event == 1)~1, data = act_data)
plot(SurvKM1$time, -log(SurvKM1$surv) , main = "Cox Snell - Weibull", xlab = "Cox Snell residuals", ylab = "-log(S(t))")
abline(a = 0, b = 1, lty = 2, lwd = 3, col = "red")
SurvKM2 <- survfit(Surv(CS3, event == 1)~1, data = act_data)
plot(SurvKM2$time, -log(SurvKM2$surv) , main = "Cox Snell - Exponential", xlab = "Cox Snell residuals", ylab = "-log(S(t))")
abline(a = 0, b = 1, lty = 2, lwd = 3, col = "red")
```


### A Graphical presentation of the log logistic model
```{r}
coef4 = coef(summary(mod_loglogistic))
scale = mod_loglogistic$scale
t = sort(act_data$time)
cd4 = c(0,50,100,150,200)
cols = 2:6

plot(0, type = 'n', 
     xlab = "Time", ylab = "Survial Prob.", main = "Log logistic survival function", xlim = c(0,360), ylim = c(0.65,1))
for (i in 1:5){
  
  Zt1 <- (log(t)-(coef4[1]+coef4[2]+coef4[3]*cd4[i]))/scale
  Zt0 <- (log(t)-(coef4[1]+coef4[3]*cd4[i]))/scale
  lines(t,1/(1+exp(Zt1)), lty = 1, col = cols[i], lwd = 2)
  lines(t, 1/(1+exp(Zt0)), lty = 2, col = cols[i], lwd = 2)
}
legend("bottomleft",legend = cd4, col = cols, lty = 1, title = "CD4 level")



 
 